## ResNet 

1. Made up of residual blocks which contains input being summed with the ouput of two convolving layers just before applying ReLU. (See fig.)

2. Solves the problem of vanishing gradients and therefore the networks can go deeper without having the vanishing gradient problem.

3. Deeper Nets are possible without having to have the problem of vanishing gradients.

![alt](resnet.png)
