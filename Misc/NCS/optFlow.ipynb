{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os \n",
    "import random\n",
    "import cv2\n",
    "import time\n",
    "#this is for directory listing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.contrib.slim as slim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path='data/'\n",
    "dir_log='log/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data and put them into three different lists\n",
    "def loadData(fileName):\n",
    "    #get the dir list\n",
    "    fileList=os.listdir(fileName)\n",
    "    fileList.sort()\n",
    "    #iterate and get them into three lists\n",
    "    img1List=[]\n",
    "    img2List=[]\n",
    "    groTruth=[]\n",
    "    print(len(fileList))\n",
    "    for i in range(0,int(len(fileList)/3)):\n",
    "        img1List.append(dir_path+fileList[3*i+1])\n",
    "        img2List.append(dir_path+fileList[3*i+2])\n",
    "        groTruth.append(dir_path+fileList[3*i])\n",
    "    return img1List,img2List,groTruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#putting all the hyperparameters\n",
    "initLr=1e-3\n",
    "epochMax=1          #max number of epocs;1 epoch=all training examples through the NN.\n",
    "epochLrDecay=5\n",
    "batchSize=4        #the batch size for every iteration. 1 epoch = 1 batch_size*iterations\n",
    "numExamples=100\n",
    "#number of training examples to use.\n",
    "useGpu=False\n",
    "W,H=512,384\n",
    "iterPerEpoch=numExamples//batchSize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the data class\n",
    "\"\"\"\n",
    "The data class will encapusulate:\n",
    "    1.reading the .flo files\n",
    "    2.hold together all the \n",
    "\"\"\"\n",
    "class Data(object):\n",
    "    def __init__(self,img1List,img2List,groTruth,bs=batchSize,shuffle=True,minusMean=True):\n",
    "        self.img1List=img1List\n",
    "        self.img2List=img2List\n",
    "        self.groTruth=groTruth\n",
    "        self.bs=bs\n",
    "        self.index=0\n",
    "        self.shuffle=shuffle #wtf is this??????\n",
    "        self.minusMean=minusMean\n",
    "        self.range=len(self.img1List)\n",
    "        self.allIndices=range(self.range)\n",
    "        \n",
    "        \n",
    "    #optical flow .flo type data reading; Courtesy - Univ. of Freiburg website.\n",
    "    def readFlow(self,name):\n",
    "        if name.endswith('.pfm') or name.endswith('.PFM'):\n",
    "            return readPFM(name)[0][:,:,0:2]\n",
    "\n",
    "        f = open(name, 'rb')\n",
    "\n",
    "        header = f.read(4)\n",
    "        if header.decode(\"utf-8\") != 'PIEH':\n",
    "            raise Exception('Flow file header does not contain PIEH')\n",
    "\n",
    "        width = np.fromfile(f, np.int32, 1).squeeze()\n",
    "        height = np.fromfile(f, np.int32, 1).squeeze()\n",
    "\n",
    "        flow = np.fromfile(f, np.float32, width * height * 2).reshape((height, width, 2))\n",
    "\n",
    "        return flow.astype(np.float32)       \n",
    "\n",
    "    \n",
    "    def upBatch(self):\n",
    "        start=self.index\n",
    "        #now point the list index to the next batch\n",
    "        self.index+=self.bs\n",
    "        #if all the batches complete, then reinitiate the indices with 0/\n",
    "        if self.index>self.range:\n",
    "            #if shuffle is set out to be true\n",
    "            if(self.shuffle):\n",
    "                random.shuffle(self.allIndices)\n",
    "                self.index=0\n",
    "                start=self.index\n",
    "                self.index+=self.bs\n",
    "        end=self.index\n",
    "        img1Batch=[]\n",
    "        img2Batch=[]\n",
    "        groTruBatch=[]\n",
    "        for i in range(start,end):\n",
    "            img1=cv2.imread(self.img1List[self.allIndices[i]]).astype(np.float32)\n",
    "            img1Batch.append(img1)\n",
    "            img2=cv2.imread(self.img2List[self.allIndices[i]]).astype(np.float32)\n",
    "            img2Batch.append(img2)\n",
    "            flow=self.readFlow(self.groTruth[self.allIndices[i]])\n",
    "            groTruBatch.append(flow)\n",
    "        return np.array(img1Batch), np.array(img2Batch),np.array(groTruBatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is hugely based on work by Lin Jian at https://github.com/linjian93/tf-flownet\n",
    "\"\"\"\n",
    "This class is going to encapsulate everything on the architecture of the \n",
    "optical flow.\n",
    "\"\"\"\n",
    "\n",
    "class Net(object):\n",
    "    def __init__(self,useGpu=True):\n",
    "        self.img1=tf.placeholder(tf.float32,[batchSize,H,W,3])\n",
    "        self.img2=tf.constant(1,shape=[batchSize, H, W, 3],dtype=tf.float32)\n",
    "        self.flow=tf.constant(1,shape=[4,H,W,2],dtype=tf.float32)\n",
    "        self.learnRate=tf.constant(0.01)\n",
    "        concat1=tf.concat([self.img1, self.img2],3,name='input')\n",
    "\n",
    "        #concat the first and second images on the third axis\n",
    "\n",
    "        #applies 64 5*5 filters\n",
    "        conv1=slim.conv2d(concat1,8,[5,5],2,scope='conv1')\n",
    "        conv2=slim.conv2d(conv1,8,[5,5],2,scope='conv2')\n",
    "        conv3=slim.conv2d(conv2,8,[5,5],2,scope='conv3')\n",
    "        conv4=slim.conv2d(conv3,8,[5,5],2,scope='conv4')\n",
    "        conv5=slim.conv2d(conv4,8,[5,5],2,scope='conv5')\n",
    "        deconv1=slim.conv2d_transpose(conv5,1,[3,3],2,scope='deconv1')\n",
    "        final = tf.reshape(deconv1, [-1,1,24*32], 'final')\n",
    "            \n",
    "        with tf.variable_scope('loss'):\n",
    "            #take the ground truth flow values and resize them \n",
    "            flow=tf.image.resize_images(self.flow,[384,512])\n",
    "            self.loss=tf.reduce_mean(tf.abs(final-tf.ones([4,24*32,1])))\n",
    "            self.merged=tf.summary.scalar('lossval',self.loss)\n",
    "        \n",
    "        #get the optimizer to run with the described learning rate\n",
    "        optimizer=tf.train.AdamOptimizer(self.learnRate)\n",
    "        \n",
    "        #encapsulating the loss and the optimizer.\n",
    "        self.trainOp=slim.learning.create_train_op(self.loss,optimizer)\n",
    "        \n",
    "        \n",
    "        #gpu settings\n",
    "        self.tf_config=tf.ConfigProto()\n",
    "        self.tf_config.gpu_options.allow_growth=True\n",
    "        if useGpu==True:\n",
    "            self.tf_config.gpu_options.visible_device_list='1'\n",
    "    \n",
    "        self.init_all=tf.global_variables_initializer()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(_):\n",
    "    #load data\n",
    "    imgList1,imgList2,floTruth=loadData('data/')\n",
    "    trainDataset=Data(imgList1,imgList2,floTruth,shuffle=True,minusMean=False)\n",
    "    \n",
    "    #call the model class\n",
    "    model=Net(useGpu=True)\n",
    "    #saver for the graph\n",
    "    saver=tf.train.Saver(max_to_keep=5)\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(model.init_all)\n",
    "        #write the file to a directory\n",
    "        writerTrain=tf.summary.FileWriter(dir_log,sess.graph)\n",
    "        #for every epoch,run the iterations for all batches\n",
    "        #xrange is being used since it uses lot less space\n",
    "        for epoch in xrange(epochMax):\n",
    "            lrDecay=0.1**(epoch/epochLrDecay)\n",
    "            learnRate=initLr*lrDecay\n",
    "            for iterations in xrange(iterPerEpoch):\n",
    "                time_start = time.time()\n",
    "                globalIter=epoch*iterPerEpoch+iterations\n",
    "                feedImg1List,feedImg2List,groTruthList=trainDataset.upBatch()\n",
    "                feedDict={model.img1:feedImg1List,model.img2:feedImg2List,\n",
    "                        model.flow:groTruthList,model.learnRate:learnRate}\n",
    "                _,mergedOut,lossOut=sess.run([model.trainOp,model.merged,model.loss],feedDict)\n",
    "                \n",
    "                writerTrain.add_summary(mergedOut,globalIter+1)\n",
    "                hour_per_epoch = iterPerEpoch * ((time.time() - time_start) / 3600)\n",
    "                print('%.2f h/epoch, epoch %03d/%03d, iter %04d/%04d, lr %.5f, loss: %.5f' %\n",
    "                      (hour_per_epoch, epoch + 1, epochMax, iterations + 1, iterPerEpoch, learnRate, lossOut))\n",
    "                \n",
    "            if not (epoch+1)%1:\n",
    "                saver.save(sess,(\"checkpoints/model\"),global_step=epoch+1)\n",
    "                tf.train.write_graph(sess.graph, \"checkpoints/\",\n",
    "                     'saved_model.pb', as_text=False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "0.00 h/epoch, epoch 001/001, iter 0001/0025, lr 0.00100, loss: 2.75190\n",
      "0.00 h/epoch, epoch 001/001, iter 0002/0025, lr 0.00100, loss: 1.66727\n",
      "0.00 h/epoch, epoch 001/001, iter 0003/0025, lr 0.00100, loss: 1.12314\n",
      "0.00 h/epoch, epoch 001/001, iter 0004/0025, lr 0.00100, loss: 0.92529\n",
      "0.00 h/epoch, epoch 001/001, iter 0005/0025, lr 0.00100, loss: 0.86887\n",
      "0.00 h/epoch, epoch 001/001, iter 0006/0025, lr 0.00100, loss: 0.87187\n",
      "0.00 h/epoch, epoch 001/001, iter 0007/0025, lr 0.00100, loss: 0.93431\n",
      "0.00 h/epoch, epoch 001/001, iter 0008/0025, lr 0.00100, loss: 0.95756\n",
      "0.00 h/epoch, epoch 001/001, iter 0009/0025, lr 0.00100, loss: 0.93524\n",
      "0.00 h/epoch, epoch 001/001, iter 0010/0025, lr 0.00100, loss: 0.94743\n",
      "0.00 h/epoch, epoch 001/001, iter 0011/0025, lr 0.00100, loss: 0.93062\n",
      "0.00 h/epoch, epoch 001/001, iter 0012/0025, lr 0.00100, loss: 0.91495\n",
      "0.00 h/epoch, epoch 001/001, iter 0013/0025, lr 0.00100, loss: 0.87749\n",
      "0.00 h/epoch, epoch 001/001, iter 0014/0025, lr 0.00100, loss: 0.84018\n",
      "0.00 h/epoch, epoch 001/001, iter 0015/0025, lr 0.00100, loss: 0.79244\n",
      "0.00 h/epoch, epoch 001/001, iter 0016/0025, lr 0.00100, loss: 0.84803\n",
      "0.00 h/epoch, epoch 001/001, iter 0017/0025, lr 0.00100, loss: 0.81893\n",
      "0.00 h/epoch, epoch 001/001, iter 0018/0025, lr 0.00100, loss: 0.79225\n",
      "0.00 h/epoch, epoch 001/001, iter 0019/0025, lr 0.00100, loss: 0.77207\n",
      "0.00 h/epoch, epoch 001/001, iter 0020/0025, lr 0.00100, loss: 0.76806\n",
      "0.00 h/epoch, epoch 001/001, iter 0021/0025, lr 0.00100, loss: 0.76883\n",
      "0.00 h/epoch, epoch 001/001, iter 0022/0025, lr 0.00100, loss: 0.75942\n",
      "0.00 h/epoch, epoch 001/001, iter 0023/0025, lr 0.00100, loss: 0.76443\n",
      "0.00 h/epoch, epoch 001/001, iter 0024/0025, lr 0.00100, loss: 0.73923\n",
      "0.00 h/epoch, epoch 001/001, iter 0025/0025, lr 0.00100, loss: 0.74971\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py:2886: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__=='__main__':\n",
    "    tf.reset_default_graph() \n",
    "    tf.app.run()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
