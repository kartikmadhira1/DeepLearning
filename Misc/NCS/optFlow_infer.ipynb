{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os \n",
    "import random\n",
    "import cv2\n",
    "import time\n",
    "#this is for directory listing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.contrib.slim as slim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path='data/'\n",
    "dir_log='log/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data and put them into three different lists\n",
    "def loadData(fileName):\n",
    "    #get the dir list\n",
    "    fileList=os.listdir(fileName)\n",
    "    fileList.sort()\n",
    "    #iterate and get them into three lists\n",
    "    img1List=[]\n",
    "    img2List=[]\n",
    "    groTruth=[]\n",
    "    print(len(fileList))\n",
    "    for i in range(0,int(len(fileList)/3)):\n",
    "        img1List.append(dir_path+fileList[3*i+1])\n",
    "        img2List.append(dir_path+fileList[3*i+2])\n",
    "        groTruth.append(dir_path+fileList[3*i])\n",
    "    return img1List,img2List,groTruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#putting all the hyperparameters\n",
    "initLr=1e-3\n",
    "epochMax=1          #max number of epocs;1 epoch=all training examples through the NN.\n",
    "epochLrDecay=5\n",
    "batchSize=1        #the batch size for every iteration. 1 epoch = 1 batch_size*iterations\n",
    "numExamples=100\n",
    "#number of training examples to use.\n",
    "useGpu=False\n",
    "W,H=512,384\n",
    "iterPerEpoch=numExamples//batchSize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the data class\n",
    "\"\"\"\n",
    "The data class will encapusulate:\n",
    "    1.reading the .flo files\n",
    "    2.hold together all the \n",
    "\"\"\"\n",
    "class Data(object):\n",
    "    def __init__(self,img1List,img2List,groTruth,bs=batchSize,shuffle=True,minusMean=True):\n",
    "        self.img1List=img1List\n",
    "        self.img2List=img2List\n",
    "        self.groTruth=groTruth\n",
    "        self.bs=bs\n",
    "        self.index=0\n",
    "        self.shuffle=shuffle #wtf is this??????\n",
    "        self.minusMean=minusMean\n",
    "        self.range=len(self.img1List)\n",
    "        self.allIndices=range(self.range)\n",
    "        \n",
    "        \n",
    "    #optical flow .flo type data reading; Courtesy - Univ. of Freiburg website.\n",
    "    def readFlow(self,name):\n",
    "        if name.endswith('.pfm') or name.endswith('.PFM'):\n",
    "            return readPFM(name)[0][:,:,0:2]\n",
    "\n",
    "        f = open(name, 'rb')\n",
    "\n",
    "        header = f.read(4)\n",
    "        if header.decode(\"utf-8\") != 'PIEH':\n",
    "            raise Exception('Flow file header does not contain PIEH')\n",
    "\n",
    "        width = np.fromfile(f, np.int32, 1).squeeze()\n",
    "        height = np.fromfile(f, np.int32, 1).squeeze()\n",
    "\n",
    "        flow = np.fromfile(f, np.float32, width * height * 2).reshape((height, width, 2))\n",
    "\n",
    "        return flow.astype(np.float32)       \n",
    "\n",
    "    \n",
    "    def upBatch(self):\n",
    "        start=self.index\n",
    "        #now point the list index to the next batch\n",
    "        self.index+=self.bs\n",
    "        #if all the batches complete, then reinitiate the indices with 0/\n",
    "        if self.index>self.range:\n",
    "            #if shuffle is set out to be true\n",
    "            if(self.shuffle):\n",
    "                random.shuffle(self.allIndices)\n",
    "                self.index=0\n",
    "                start=self.index\n",
    "                self.index+=self.bs\n",
    "        end=self.index\n",
    "        img1Batch=[]\n",
    "        img2Batch=[]\n",
    "        groTruBatch=[]\n",
    "        for i in range(start,end):\n",
    "            img1=cv2.imread(self.img1List[self.allIndices[i]]).astype(np.float32)\n",
    "            img1Batch.append(img1)\n",
    "            img2=cv2.imread(self.img2List[self.allIndices[i]]).astype(np.float32)\n",
    "            img2Batch.append(img2)\n",
    "            flow=self.readFlow(self.groTruth[self.allIndices[i]])\n",
    "            groTruBatch.append(flow)\n",
    "        return np.array(img1Batch), np.array(img2Batch),np.array(groTruBatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#this is hugely based on work by Lin Jian at https://github.com/linjian93/tf-flownet\n",
    "\"\"\"\n",
    "This class is going to encapsulate everything on the architecture of the \n",
    "optical flow.\n",
    "\"\"\"\n",
    "\n",
    "class Net(object):\n",
    "    def __init__(self,useGpu=True):\n",
    "        self.img1=tf.placeholder(tf.float32,[1,H,W,3])\n",
    "        self.img2=tf.constant(1,shape=[1, H, W, 3],dtype=tf.float32)\n",
    "        self.flow=tf.constant(1,shape=[1,H,W,2],dtype=tf.float32)\n",
    "        self.learnRate=tf.constant(0.01)\n",
    "        concat1=tf.concat([self.img1, self.img2],3,name='input')\n",
    "\n",
    "        #concat the first and second images on the third axis\n",
    "\n",
    "        #applies 64 5*5 filters\n",
    "        conv1=slim.conv2d(concat1,8,[5,5],2,scope='conv1')\n",
    "        conv2=slim.conv2d(conv1,8,[5,5],2,scope='conv2')\n",
    "        conv3=slim.conv2d(conv2,8,[5,5],2,scope='conv3')\n",
    "        conv4=slim.conv2d(conv3,8,[5,5],2,scope='conv4')\n",
    "        conv5=slim.conv2d(conv4,8,[5,5],2,scope='conv5')\n",
    "        deconv1=slim.conv2d_transpose(conv5,1,[3,3],2,scope='deconv1')\n",
    "        final = tf.reshape(deconv1, [1,1,24*32], 'final')\n",
    "        print(np.shape(final))\n",
    "        \n",
    "        #gpu settings\n",
    "        self.tf_config=tf.ConfigProto()\n",
    "        self.tf_config.gpu_options.allow_growth=True\n",
    "        if useGpu==True:\n",
    "            self.tf_config.gpu_options.visible_device_list='1'\n",
    "    \n",
    "        self.init_all=tf.global_variables_initializer()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(_):\n",
    "    #load data\n",
    "    imgList1,imgList2,floTruth=loadData('data/')\n",
    "    trainDataset=Data(imgList1,imgList2,floTruth,shuffle=True,minusMean=False)\n",
    "    \n",
    "    #call the model class\n",
    "    model=Net(useGpu=True)\n",
    "    #saver for the graph\n",
    "    saver=tf.train.Saver()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, \"./checkpoints/model-1\")\n",
    "        saver.save(sess, \"./checkpoints/inference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "(1, 1, 768)\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoints/model-1\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py:2886: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__=='__main__':\n",
    "    tf.reset_default_graph() \n",
    "    tf.app.run()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "ph = tf.placeholder(shape=[None,3], dtype=tf.int32)\n",
    "\n",
    "# look the -1 in the first position\n",
    "x = tf.slice(ph, [0, 0], [-1, 2])\n",
    "\n",
    "input_ = np.array([[1,2,3],\n",
    "                   [3,4,5],\n",
    "                   [5,6,7]])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "        print(sess.run(x, feed_dict={ph: input_}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=xrange(4)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
